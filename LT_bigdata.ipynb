{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import copy\n",
    "import pickle\n",
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "vocab_to_int = copy.copy(CODES)\n",
    "counter = 4\n",
    "with open(\"data/training-giga-fren/giga-fren.release2.fixed.en\", encoding='utf-8') as infile:\n",
    "    for line in infile:\n",
    "        line = line.lower()\n",
    "        for word in line.split():\n",
    "            if word in vocab_to_int:  \n",
    "                continue  \n",
    "            else:   \n",
    "                vocab_to_int[word] = counter\n",
    "                counter += 1\n",
    "pickle.dump( vocab_to_int, open( \"en_vocab_to_int.pkl\", \"wb\" ) )\n",
    "#new_vocab = pickle.load( open( \"vocab_to_int.pkl\", \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab_to_int = pickle.load( open( \"en_vocab_to_int.pkl\", \"rb\" ) )\n",
    "with open(\"data/training-giga-fren/giga-fren.release2.fixed.en\", encoding='utf-8') as infile2:\n",
    "    for line2 in infile2:\n",
    "        line2 = line2.lower()\n",
    "        for word2 in line2.split():\n",
    "            source_id_text.append(vocab_to_int[word2]) \n",
    "pickle.dump((source_id_text,vocab_to_int), open( \"en_source_txt.pkl\", \"wb\" ) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "vocab_to_int = copy.copy(CODES)\n",
    "counter = 4\n",
    "with open(\"data/training-giga-fren/giga-fren.release2.fixed.fr\", encoding='utf-8') as infile:\n",
    "    for line in infile:\n",
    "        line = line.lower()\n",
    "        for word in line.split():\n",
    "            if word in vocab_to_int:  \n",
    "                continue  \n",
    "            else:   \n",
    "                vocab_to_int[word] = counter\n",
    "                counter += 1\n",
    "pickle.dump( vocab_to_int, open( \"fr_vocab_to_int.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "target_id_text =[]\n",
    "vocab_to_int = pickle.load( open( \"fr_vocab_to_int.pkl\", \"rb\" ) )\n",
    "with open(\"data/training-giga-fren/giga-fren.release2.fixed.fr\", encoding='utf-8') as infile2:\n",
    "    for line2 in infile2:\n",
    "        line2 = line2.lower()\n",
    "        for word2 in line2.split():\n",
    "            target_id_text.append(vocab_to_int[word2]) \n",
    "pickle.dump((target_id_text,vocab_to_int), open( \"fr_target_txt.pkl\", \"wb\" ) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1.0-cpu]",
   "language": "python",
   "name": "conda-env-tensorflow1.0-cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
